{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0ff02f05",
      "metadata": {
        "id": "0ff02f05"
      },
      "source": [
        "# Session 3 - Random Forest Model Tuning\n",
        "\n",
        "This is an introductory notebook to familiarize yourself with optimization techniques for Machine Learning (ML). For this work, we will use data from the Moderate Resolution Imaging Spectroradiometer (MODIS) instrument  and a Random Forest algorithm to perform water classification. This same workflow can be adapted to other applications and by using other algorithms.\n",
        "\n",
        "Author: Caleb S. Spradlin, Jordan A. Caraballo-Vega\n",
        "Release Date: 2023.04.08\n",
        "Last Modified: 2023.04.08\n",
        "\n",
        "## 1. Import Libraries\n",
        "\n",
        "In this section we import the Python libraries to use during the development of this notebook. The default Python kernel from Google Colab does not include all fo the packages we need, thus we proceed to install them via pip.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/NASAARSET/ARSET_ML_Fundamentals/main/src/folium_helper.py"
      ],
      "metadata": {
        "id": "wsym78i5qADn"
      },
      "id": "wsym78i5qADn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets optuna rasterio pyproj"
      ],
      "metadata": {
        "id": "gcGaGk31yAAS"
      },
      "id": "gcGaGk31yAAS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import datetime\n",
        "import glob\n",
        "import joblib\n",
        "import numpy as np\n",
        "import datasets\n",
        "import pandas as pd\n",
        "from pathlib import Path   \n",
        "import optuna\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.ensemble import RandomForestClassifier as skRF\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, f1_score\n",
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn.inspection import permutation_importance\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "# Geospatial related imports\n",
        "from osgeo import gdalconst\n",
        "from osgeo import gdal\n",
        "import folium\n",
        "from folium import plugins\n",
        "import folium_helper\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "g08D1b9_x6Sk"
      },
      "id": "g08D1b9_x6Sk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define General Variables\n",
        "\n",
        "In this section we define general variables to work with through this notebook. A description of each variable is listed below as a comment next to the variable definition."
      ],
      "metadata": {
        "id": "w-YuNpcUyOjK"
      },
      "id": "w-YuNpcUyOjK"
    },
    {
      "cell_type": "code",
      "source": [
        "FIGURE_OUTPUT_DIR = 'output'\n",
        "RASTER_OUTPUT_DIR = 'output'\n",
        "MODEL_OUTPUT_DIR = 'models'\n",
        "\n",
        "# url of the dataset we will be using, this is a link to the Hugging Face repository\n",
        "# of this tutorial\n",
        "DATASET_URL = 'nasa-cisto-data-science-group/modis-lake-powell-toy-dataset'\n",
        "\n",
        "TILE = 'global'\n",
        "MODEL = 'rf'\n",
        "TEST_RATIO = 0.2\n",
        "RANDOM_STATE = 42\n",
        "LABEL_NAME = 'water'\n",
        "DATA_TYPE = np.int16\n",
        "colsToDrop = []#['x_offset', 'y_offset']\n",
        "v_names = ['sur_refl_b01_1','sur_refl_b02_1','sur_refl_b03_1',\n",
        "           'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
        "           'sur_refl_b07_1','ndvi','ndwi1','ndwi2']\n",
        "\n"
      ],
      "metadata": {
        "id": "uR79V4_oyTOf"
      },
      "id": "uR79V4_oyTOf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we create an output directory to store any artifacts out of our models and visualizations."
      ],
      "metadata": {
        "id": "V5Og37_Tyfx1"
      },
      "id": "V5Og37_Tyfx1"
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(FIGURE_OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "NWe5GCYMyf89"
      },
      "id": "NWe5GCYMyf89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "Read in to cuDF or pandas Dataframe\n",
        "Drop unnecessary columns\n",
        "Clean data\n",
        "Split into Xs and Ys\n",
        "Train-test split"
      ],
      "metadata": {
        "id": "Exyc3rltyv5U"
      },
      "id": "Exyc3rltyv5U"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_dataset = pd.DataFrame(datasets.load_dataset(DATASET_URL, split='train'))\n",
        "test_dataset = pd.DataFrame(datasets.load_dataset(DATASET_URL, split='test'))"
      ],
      "metadata": {
        "id": "0LPoZPlcywh9"
      },
      "id": "0LPoZPlcywh9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = train_dataset.drop(['water'], axis=1), train_dataset['water']\n",
        "X_test, y_test = test_dataset.drop(['water'], axis=1), test_dataset['water']\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "t8QRk_rhy3T5"
      },
      "id": "t8QRk_rhy3T5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = [print(column) for column in X_train.columns]\n"
      ],
      "metadata": {
        "id": "VaZxVF5hy54X"
      },
      "id": "VaZxVF5hy54X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.describe().T"
      ],
      "metadata": {
        "id": "j0VFtErqy-hj"
      },
      "id": "j0VFtErqy-hj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_interesting_idx(df, column, threshold, greaterThan=True):\n",
        "    dfToReturn = df[df[column] > threshold] if \\\n",
        "        greaterThan else df[df[column] < threshold]\n",
        "    return dfToReturn"
      ],
      "metadata": {
        "id": "C01aTuZgzEdx"
      },
      "id": "C01aTuZgzEdx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_interesting_idx(X_train, 'ndvi', 10000)\n"
      ],
      "metadata": {
        "id": "0QDdWSIZzFYV"
      },
      "id": "0QDdWSIZzFYV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_interesting_idx(X_train, 'ndwi1', 10000)\n"
      ],
      "metadata": {
        "id": "zofZcXJWzIfv"
      },
      "id": "zofZcXJWzIfv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_interesting_idx(X_train, 'ndwi2', 10000)\n"
      ],
      "metadata": {
        "id": "yicRig1tzNny"
      },
      "id": "yicRig1tzNny",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model definition and training\n",
        "Set TREES_ONLY to True if you only want to tune number of estimators, else max_depth, max_samples_split, min_samples_leaf will be tuned as well."
      ],
      "metadata": {
        "id": "0ALKmhxBzQ8k"
      },
      "id": "0ALKmhxBzQ8k"
    },
    {
      "cell_type": "code",
      "source": [
        "TREES_ONLY = True"
      ],
      "metadata": {
        "id": "b9_u4pJazSRL"
      },
      "id": "b9_u4pJazSRL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
        "    max_depth = [80, 90, 100, 110]\n",
        "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
        "    min_samples_split = [2, 4, 8, 10]\n",
        "    bootstrap = [True, False]\n",
        "    \n",
        "    if TREES_ONLY:\n",
        "        param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
        "                   'criterion':'gini', \n",
        "                   'max_depth':None, \n",
        "                   'min_samples_split':2, \n",
        "                   'min_samples_leaf':1, \n",
        "                   'min_weight_fraction_leaf':0.0, \n",
        "                   'max_features':'auto', \n",
        "                   'max_leaf_nodes':None, \n",
        "                   'min_impurity_decrease':0.0, \n",
        "                   'bootstrap':True, \n",
        "                   'oob_score':False, \n",
        "                   'n_jobs':-1, \n",
        "                   'random_state':42, \n",
        "                   'verbose':0, \n",
        "                   'warm_start':True, \n",
        "                   'class_weight':None, \n",
        "                   'ccp_alpha':0.0, \n",
        "                   'max_samples':None\n",
        "                      }\n",
        "    else:\n",
        "        param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
        "                       'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
        "                       'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
        "                       'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
        "                       'bootstrap': True,\n",
        "                       'criterion':'gini', \n",
        "                       'min_weight_fraction_leaf':0.0, \n",
        "                       'max_features':'auto', \n",
        "                       'max_leaf_nodes':None, \n",
        "                       'min_impurity_decrease':0.0, \n",
        "                       'oob_score':False, \n",
        "                       'n_jobs':-1, \n",
        "                       'random_state':42, \n",
        "                       'verbose':0, \n",
        "                       'warm_start':False, \n",
        "                       'class_weight':None, \n",
        "                       'ccp_alpha':0.0, \n",
        "                       'max_samples':None\n",
        "                      }\n",
        "    \n",
        "    rf = skRF(**param)\n",
        "    rf.fit(X_train, y_train)\n",
        "    preds = rf.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    fp = cm[1][0]\n",
        "    precision = precision_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    del rf, preds, cm\n",
        "    return precision, f1, fp\n",
        "\n",
        "metric = {'precision': 0, 'f1': 1, 'false_positive': 2}"
      ],
      "metadata": {
        "id": "QGjQwU50zUds"
      },
      "id": "QGjQwU50zUds",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start hyperparameter tuning trials.\n",
        "Ex output: Trial 0 finished with values: [0.9527224325581133, 0.9667626330841518, 9684.0] and parameters:\n",
        "\n",
        "The metrics in order are: [precision, f1, false positives]"
      ],
      "metadata": {
        "id": "FGLT5oYDzZx4"
      },
      "id": "FGLT5oYDzZx4"
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "study = optuna.create_study(study_name='rf_tuning', directions=['maximize','maximize','minimize'])\n",
        "study.optimize(objective, n_trials=25, timeout=20*60)"
      ],
      "metadata": {
        "id": "NVyud8sWzX3t"
      },
      "id": "NVyud8sWzX3t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get metrics from the overall hyperparameter tuning\n"
      ],
      "metadata": {
        "id": "tEP2s-TpzjV5"
      },
      "id": "tEP2s-TpzjV5"
    },
    {
      "cell_type": "code",
      "source": [
        "METRIC_TO_USE = 'f1'# out of 'precision', 'f1', 'false_positive'"
      ],
      "metadata": {
        "id": "QyVpCvqvziOg"
      },
      "id": "QyVpCvqvziOg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "print(\"Using {} idx: {}\".format(METRIC_TO_USE, metric[METRIC_TO_USE]))\n",
        "trials = study.best_trials\n",
        "if METRIC_TO_USE == 'false_positive' or METRIC_TO_USE == 'false_negative':\n",
        "    trial_score = min([trial.values[metric[METRIC_TO_USE]] for trial in trials])\n",
        "else:\n",
        "    trial_score = max([trial.values[metric[METRIC_TO_USE]] for trial in trials])\n",
        "best_trial_params = [trial.params for trial in trials if trial.values[metric[METRIC_TO_USE]] == trial_score][0]\n",
        "best_trial = [trial for trial in trials if trial.values[metric[METRIC_TO_USE]] == trial_score][0]\n",
        "print(best_trial_params)\n",
        "print(trial_score)\n",
        "\n",
        "trial_scores = [trial.values for trial in trials]\n",
        "trial_params = [trial.params for trial in trials]\n",
        "\n",
        "for score, param in zip(trial_scores, trial_params):\n",
        "    print(score)\n",
        "    for k, v in param.items():\n",
        "        print(\"     {}: {}\".format(k, v))\n",
        "\n",
        "study_df = study.trials_dataframe()\n",
        "study_df.to_csv(\"hyperopt_tuning_trial_{}_random_forest.csv\".format(\n",
        "    datetime.datetime.now().strftime('%Y_%m_%d_%H_%M')))"
      ],
      "metadata": {
        "id": "QHP6mRHczm5_"
      },
      "id": "QHP6mRHczm5_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the optimization history\n"
      ],
      "metadata": {
        "id": "AsMOY1Apzqqr"
      },
      "id": "AsMOY1Apzqqr"
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.matplotlib.plot_optimization_history(study, target=lambda t: t.values[metric[METRIC_TO_USE]])"
      ],
      "metadata": {
        "id": "nUomqzR7zo2B"
      },
      "id": "nUomqzR7zo2B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize hyperparameter importances\n"
      ],
      "metadata": {
        "id": "NGfVA62xztZT"
      },
      "id": "NGfVA62xztZT"
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.matplotlib.plot_param_importances(study, target=lambda t: t.values[metric[METRIC_TO_USE]])"
      ],
      "metadata": {
        "id": "46kpki3dzuCR"
      },
      "id": "46kpki3dzuCR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the loss functions compares to number of estimators during tuning\n"
      ],
      "metadata": {
        "id": "DzBcQKUBzxBD"
      },
      "id": "DzBcQKUBzxBD"
    },
    {
      "cell_type": "code",
      "source": [
        "udf = study_df.drop_duplicates(['params_n_estimators']).sort_values(by='params_n_estimators')\n",
        "udf_by_score = udf[udf.values_0 == udf.values_0.max()]\n",
        "udf"
      ],
      "metadata": {
        "id": "VrB7n6zZzx7Q"
      },
      "id": "VrB7n6zZzx7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TREES_ONLY:\n",
        "    udf = study_df.drop_duplicates(['params_n_estimators']).sort_values(by='params_n_estimators')\n",
        "    udf_by_score = udf[udf.values_0 == udf.values_0.max()]\n",
        "    fig, ax = plt.subplots(3, figsize=(12,15))\n",
        "    ax[0].plot(udf['params_n_estimators'], udf['values_0'], label='Precision per n estimators')\n",
        "    ax[0].set_xlabel('Number of Estimators')\n",
        "    ax[0].set_ylabel('Precision Score')\n",
        "    ax[1].plot(udf['params_n_estimators'], udf['values_1'], label='F1 score per n estimators')\n",
        "    ax[1].set_xlabel('Number of Estimators')\n",
        "    ax[1].set_ylabel('F1 Score')\n",
        "    ax[2].plot(udf['params_n_estimators'], udf['values_2'], label='False positives per n estimators')\n",
        "    ax[2].set_xlabel('Number of estimators')\n",
        "    ax[2].set_ylabel('False Positives')"
      ],
      "metadata": {
        "id": "mXxMkjKaz73S"
      },
      "id": "mXxMkjKaz73S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model with the best hyperparamers\n"
      ],
      "metadata": {
        "id": "yh0AxnY3z_og"
      },
      "id": "yh0AxnY3z_og"
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = best_trial_params\n",
        "hyperparameters['n_jobs'] = -1\n",
        "hyperparameters['warm_start'] = True\n",
        "print('Using these params:')\n",
        "pprint(hyperparameters)\n",
        "classifier = skRF(**hyperparameters)"
      ],
      "metadata": {
        "id": "oloXYv23z87Y"
      },
      "id": "oloXYv23z87Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5)\n",
        "kf.get_n_splits(X_train)"
      ],
      "metadata": {
        "id": "cRTbwRpP6Zuz"
      },
      "id": "cRTbwRpP6Zuz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestModel = None\n",
        "bestModelScore = 0\n",
        "scores = []\n",
        "for trainIdx, testIdx in kf.split(X_train):\n",
        "    print(\"Train {}, Test {}\".format(trainIdx, testIdx))\n",
        "    X_train_valid, X_test_valid = X_train.iloc[trainIdx], X_train.iloc[testIdx]\n",
        "    y_train_valid, y_test_valid = y_train.iloc[trainIdx], y_train.iloc[testIdx]\n",
        "    print('Fitting model')\n",
        "    classifier.fit(X_train_valid, y_train_valid)\n",
        "    print('Getting score')\n",
        "    score = classifier.score(X_test_valid, y_test_valid)\n",
        "    if score>=bestModelScore:\n",
        "        bestModelScore = score\n",
        "        print('Training accuracy score: {}'.format(score))\n",
        "        bestModel = classifier\n",
        "    print('Predicting for test set')\n",
        "    test_predictions = classifier.predict(X_test_valid)\n",
        "    print(classification_report(y_test_valid, test_predictions))\n",
        "    print('Score: {}'.format(score))\n",
        "    scores.append(score)\n",
        "    del test_predictions, score"
      ],
      "metadata": {
        "id": "fPaB07et0Dn-"
      },
      "id": "fPaB07et0Dn-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoreAvg = np.asarray(scores).mean()\n",
        "print('Average accuracy score: {}'.format(scoreAvg))\n",
        "print('Best accuracy score: {}'.format(bestModelScore))"
      ],
      "metadata": {
        "id": "FkUWSV7OCu3l"
      },
      "id": "FkUWSV7OCu3l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = bestModel"
      ],
      "metadata": {
        "id": "RoJE7VjUC579"
      },
      "id": "RoJE7VjUC579",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = classifier.score(X_test, y_test)\n",
        "score = round(score, 3)\n",
        "score"
      ],
      "metadata": {
        "id": "7KRWowyhC7Jt"
      },
      "id": "7KRWowyhC7Jt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = classifier.predict(X_train)\n",
        "test_predictions = classifier.predict(X_test)\n",
        "prediction_probs = classifier.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "Ybljl8QdC-6J"
      },
      "id": "Ybljl8QdC-6J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_predictions.astype(np.int16)\n",
        "y_test_int = y_test.astype(np.int16)"
      ],
      "metadata": {
        "id": "qMrzYtZiDDOW"
      },
      "id": "qMrzYtZiDDOW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Performance')\n",
        "print('-------------------------------------------------------')\n",
        "print(classification_report(y_train, train_predictions))\n",
        "print('Test Performance')\n",
        "print('-------------------------------------------------------')\n",
        "print(classification_report(y_test, test_predictions))\n",
        "cm = confusion_matrix(y_test_int, test_predictions)\n",
        "recall = (cm[0][0] / (cm[0][0] + cm[0][1]))\n",
        "print('Test Recall')\n",
        "print('-------------------------------------------------------')\n",
        "print(recall)\n",
        "print('Confusion Matrix')\n",
        "print('-------------------------------------------------------')\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "ThzXO0drDIU4"
      },
      "id": "ThzXO0drDIU4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "permutation_importance_results = permutation_importance(classifier,\n",
        "                                                        X=X_test,\n",
        "                                                        y=y_test,\n",
        "                                                        n_repeats=10,\n",
        "                                                        random_state=42)"
      ],
      "metadata": {
        "id": "EQSQR8doDK7r"
      },
      "id": "EQSQR8doDK7r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_idx = permutation_importance_results.importances_mean.argsort()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.barh(X_test.columns[sorted_idx], permutation_importance_results.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")"
      ],
      "metadata": {
        "id": "5dD0QWTRDNUg"
      },
      "id": "5dD0QWTRDNUg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train, X_test, y_train, y_test, test_predictions, train_predictions, prediction_probs, y_test_int\n"
      ],
      "metadata": {
        "id": "zTziDUD1DPlu"
      },
      "id": "zTziDUD1DPlu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = './water_classifier_rf_cpu.sav'\n",
        "print('Saving model to: {}'.format(model_save_path))\n",
        "print(classifier)\n",
        "joblib.dump(classifier, model_save_path, compress=3)"
      ],
      "metadata": {
        "id": "hBE3080EDSEP"
      },
      "id": "hBE3080EDSEP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "powell_dataset = snapshot_download(repo_id=DATASET_URL, allow_patterns=\"*.tif\", repo_type='dataset')\n",
        "fileList = sorted([file for file in glob.glob(os.path.join(powell_dataset, 'IL.*.Powell.*.tif')) if 'sur_refl' in file])\n",
        "fileList"
      ],
      "metadata": {
        "id": "kXGfYaLZj58Z"
      },
      "id": "kXGfYaLZj58Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readRastersToArray(fileList):\n",
        "    rasterProjection = None\n",
        "    newshp = (1300*1300, 10)\n",
        "    img = np.empty(newshp, dtype=np.int16)\n",
        "    for i, fileName in enumerate(fileList):\n",
        "        ds = gdal.Open(fileName)\n",
        "        img[:, i] = ds.GetRasterBand(1).ReadAsArray().astype(np.int16).ravel()\n",
        "        if i == 0:\n",
        "            rasterProjection = ds.GetProjection()\n",
        "        ds = None\n",
        "    img[:, len(fileList)] = ((img[:, 1] - img[:, 0]) / (img[:, 1] + img[:, 0])) * 10000\n",
        "    img[:, len(fileList)+1] = ((img[:, 1] - img[:, 5]) / (img[:, 1] + img[:, 5])) * 10000\n",
        "    img[:, len(fileList)+2] = ((img[:, 1] - img[:, 6]) / (img[:, 1] + img[:, 6])) * 10000\n",
        "    return img, rasterProjection"
      ],
      "metadata": {
        "id": "JVBzYlypmgKJ"
      },
      "id": "JVBzYlypmgKJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "im, rasterProjection = readRastersToArray(fileList)\n",
        "print('Raster as ndarray')\n",
        "print(im)\n",
        "print('{} MB size'.format((im.size * im.itemsize) / 1000000))"
      ],
      "metadata": {
        "id": "nyMR41rEmkbz"
      },
      "id": "nyMR41rEmkbz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predictRaster(img_chunk, colsToDrop=None):\n",
        "    \"\"\"\n",
        "    Function given a raster in the form of a nxn matrix, will\n",
        "    convert the matrix to a GPU-bound data frame then perform \n",
        "    predictions given the loaded model.\n",
        "    \n",
        "    Return the prediction matrix, the prediction probabilities\n",
        "    for each and the dataframe converted to host.\n",
        "    \"\"\"\n",
        "    print('Converting host array to CPU-based dataframe')\n",
        "    df = pd.DataFrame(img_chunk, columns=v_names, dtype=np.float32)\n",
        "    df = df.drop(columns=colsToDrop)\n",
        "    print('Making predictions from raster')\n",
        "    predictions = classifier.predict(df)\n",
        "    predictionsProbs = classifier.predict_proba(df)\n",
        "    return predictions, predictionsProbs, df"
      ],
      "metadata": {
        "id": "eslsDUyVmpFz"
      },
      "id": "eslsDUyVmpFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predictedRaster, predictedProbaRaster, df = predictRaster(im, colsToDrop)"
      ],
      "metadata": {
        "id": "Urcqxwaamt29"
      },
      "id": "Urcqxwaamt29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shp = (1300, 1300)\n",
        "left = list()\n",
        "right = list()\n",
        "for i, subarr in enumerate(predictedProbaRaster):\n",
        "    left.append(subarr[0])\n",
        "    right.append(subarr[1])\n",
        "leftArr = np.asarray(left)\n",
        "rightArr = np.asarray(right)\n",
        "probaLand = leftArr.reshape(shp)\n",
        "probaWater = rightArr.reshape(shp)"
      ],
      "metadata": {
        "id": "EiUEE7gdmwwp"
      },
      "id": "EiUEE7gdmwwp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shp = (1300, 1300)\n",
        "matrix = np.asarray(predictedRaster)\n",
        "reshp = matrix.reshape(shp)\n",
        "reshp.shape"
      ],
      "metadata": {
        "id": "zknJ51Ftmzhf"
      },
      "id": "zknJ51Ftmzhf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = [file for file in glob.glob(os.path.join(powell_dataset, '*.tif')) if 'qa' in file][0]\n",
        "ds = gdal.Open(qa)\n",
        "qaMask = ds.GetRasterBand(1).ReadAsArray()\n",
        "output = np.where(qaMask == 0, reshp, -9999)\n",
        "qaMask"
      ],
      "metadata": {
        "id": "_kd5GQTHm2Rj"
      },
      "id": "_kd5GQTHm2Rj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countNoData = np.count_nonzero(output == -9999)\n",
        "countLand = np.count_nonzero(output == 0)\n",
        "countWater = np.count_nonzero(output == 1)\n",
        "print('Predicted\\n No-data occuraces: {}\\n Land occurances: {}\\n Water occurances: {}'.format(countNoData, countLand, countWater))"
      ],
      "metadata": {
        "id": "J4tbrTNSnOwU"
      },
      "id": "J4tbrTNSnOwU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geoTransform = (-9961223.407, 231.65635, 0.0, 4285642.633667, 0.0, -231.65635)\n"
      ],
      "metadata": {
        "id": "6fRYBhjXnR9Q"
      },
      "id": "6fRYBhjXnR9Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictedPath = os.path.join(RASTER_OUTPUT_DIR, 'PowellPredictedWaterMask.tif')\n",
        "\n",
        "driver = gdal.GetDriverByName('GTiff')\n",
        "outDs = driver.Create(predictedPath, 1300, 1300, 1, gdal.GDT_Int16, options=['COMPRESS=LZW'])\n",
        "outDs.SetGeoTransform(geoTransform)\n",
        "outDs.SetProjection(rasterProjection)\n",
        "outBand = outDs.GetRasterBand(1)\n",
        "outBand.WriteArray(output)\n",
        "outBand.SetNoDataValue(-9999)\n",
        "outDs.FlushCache()\n",
        "outDs = None\n",
        "outBand = None\n",
        "driver = None"
      ],
      "metadata": {
        "id": "nttoP_ZTncfA"
      },
      "id": "nttoP_ZTncfA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mask_3857 = folium_helper.reproject_to_3857(predictedPath)\n",
        "mask_d = folium_helper.get_bounds(mask_3857)\n",
        "mask_b1 = folium_helper.open_and_get_band(mask_3857, 1)\n",
        "folium_helper.cleanup(mask_3857)\n",
        "mask_b1 = np.where(mask_b1 == -9999, 0, mask_b1)\n",
        "zeros = np.zeros_like(mask_b1)\n",
        "mask_rgb = np.dstack((mask_b1, zeros, zeros))"
      ],
      "metadata": {
        "id": "YLoJwlHDnsJZ"
      },
      "id": "YLoJwlHDnsJZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = folium.Map(location=[mask_d['center'][1], mask_d['center'][0]],\n",
        "                   tiles='https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}', zoom_start = 6, attr='Google')"
      ],
      "metadata": {
        "id": "S-qWzdWDntDm"
      },
      "id": "S-qWzdWDntDm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.add_child(folium_helper.get_overlay(mask_rgb, mask_d, 'Water classification RF predicted mask', opacity=0.6))\n",
        "m.add_child(plugins.MousePosition())\n",
        "m.add_child(folium.LayerControl())"
      ],
      "metadata": {
        "id": "qob9SRCKnwIK"
      },
      "id": "qob9SRCKnwIK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}